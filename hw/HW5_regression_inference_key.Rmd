---
title: "HW5_regression_inference"
author: "Darrell Sonntag"
date: "2024-02-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(patchwork)
library(moderndive)
```

Fit a multiple linear regression model to conduct statistical inference.

Do vehicles that pass emissions have lower emissions than those that don't?

First, we are going to control for multiple factors that impact emissions

We will visually evaluate the impact that potential factors such as model year, location, fuel type and vehicle emission tests have on emissions

Then, we'll fit a multiple linear regression to see if the vehicle emission test status has an impact on emissions.

First read in the data

summer.2022.IM.csv summer.2022.nonIM

In the data folder in the class public repository,

```{r}

summer.2022.IM <- read_csv("./data/summer.2022.IM.csv") 

summer.2022.nonIM <- read_csv("./data/summer.2022.nonIM.csv") 

## combine summer.2022.IM and summer.2022.nonIM 

summer.2022 <- bind_rows(summer.2022.IM, summer.2022.nonIM)



```

This file includes the 4 dates of vehicle measurements from summer 2022. Amber has updated the files to include data on whether the vehicle is current with it's vehicle emission test requirement

Combine the two data files using bind_rows

```{r}
summer.2022 <- bind_rows(summer.2022.IM, summer.2022.nonIM)
```

Reorder the compliance variable, Compliant, Not Compliant, Exempt, and NonIM

Calculate the a Complicance variable as a factor with levels Compliant, Not Compliant, Exempt, NonIM (but set ordered = False) (This is so the regression we will calculate later on, doesn't think there is an order to the factors)

```{r}
summer.2022 <- summer.2022 %>%
  mutate(Compliance = factor(Compliance, levels = c("Compliant", "Not Compliant", "Exempt", "NonIM"), ordered = F))

```

Just filter to the gasoline vehicles Add a variable called year_cuts Use the cut function to cut the Year variable, into intervals between the following break points: 1963, 1982, 1994, 2001, 2016, and 2023.

?cut

```{r}
summer.2022.gas <- summer.2022 %>%
  filter(FuelGroup == "Gasoline") %>%
  filter(!is.na(Year)) %>% 
  mutate(year_cuts = cut(Year, breaks = c(1963, 1982, 1994, 2001, 2016, 2023))) 
```

Calculate mean, count, sd, and 95% CI by pollutant, year_cuts, and compliance

```{r}
summer.2022.compliance.summary <- summer.2022.gas %>%
  group_by(pollutant, Compliance, year_cuts) %>%
  summarize(mean = mean(ER, na.rm=T),median = median(ER,na.rm=T),
            sd=sd(ER,na.rm=T),n=sum(!is.na(ER)),
            min=min(ER,na.rm=T),max=max(ER,na.rm=T)) %>%
  mutate(tcrit = qt(.975,df=(n-1))) %>%
  mutate(bound = tcrit*sd/sqrt(n)) %>%
  mutate(lower.95 = mean-bound) %>%
  mutate(upper.95 = mean+bound)

```

Look at the summary file - How many exempt vehicles are there with CO measurements? - Only 11 vehicles

Graph the means with year_cuts on the x-axis

-   Using geom_col, with dodge to plot all the compliance levels
-   Different colors for compliance
-   Year cuts on the x-axis
-   Dodge the compliance
-   Separate panels for each pollutant

```{r}
names(summer.2022.compliance.summary)

ggplot(data = summer.2022.compliance.summary,aes(x = year_cuts, y = mean, fill= Compliance)) +
geom_col(position = position_dodge(width = 1)) +
    geom_errorbar(position = position_dodge(width = 1), aes(ymin = lower.95, ymax = upper.95), width = 0.2) +
facet_wrap(~ pollutant, scales = "free_y") +
labs( x = "MY groups",
     y = "Emissions Rate") +
theme(axis.text.x = element_text(size=8, angle=90,hjust = 1, vjust =0.2))

```
Plot again, but just for 1994 and later model year groups

-   Just plot CO, HC, NH3, and NO,
-   Use geom_errorbar to add 95% confidence intervals to the plot

Also just plot the "Compliant", "Not Compliant","NonIM")

Re-create the following graph using ggplot

![](../../CE594R_data_science_R/figs/ER_compliance.png)

```{r}
names(summer.2022.compliance.summary)


summer.2022.compliance.summary %>%
  filter(pollutant %in% c('CO','HC','NH3','NO')) %>%
  filter(Compliance %in% c("Compliant", "Not Compliant","NonIM")) %>%
  filter(year_cuts %in% c("(1994,2001]", "(2001,2016]" ,"(2016,2023]")) %>%
  ggplot(aes(x = year_cuts, y = mean, fill= Compliance)) +
  geom_col(position = position_dodge(width = 1)) +
  geom_errorbar(position = position_dodge(width = 1), aes(ymin = lower.95, ymax = upper.95), width = 0.2) +
  facet_wrap(~ pollutant, scales = "free_y") +
  labs(title = "Comparison of Emissions Rates by Compliance",
       x = "Compliance Status",
       y = "Emissions Rate") +
  theme(axis.text.x = element_text(size=8, angle=90,hjust = 1, vjust =0.2))

ggsave("../../CE594R_data_science_R/figs/ER_compliance.png")

```


Do you observe any systematic or significant differences in mean Not Compliant or NonIM emission rates compared to the Compliant emission rates?

For the 1994-2001, the NonIM vehicles tend to be higher than the Compliant vehicles for all for CO, HC, NH3, and NO. However, the difference only appears significant for HC. For the newer model year groups, The Compliant means tends to be the lowest for all pollutants, but it is not significantly different.

Let's look at some potential confounding variables:

Let's plot the mean emission rates by year_cut and by location

```{r}

summer.2022.loc.summary <- summer.2022.gas %>%
  group_by(pollutant, location, year_cuts) %>%
  summarize(mean = mean(ER, na.rm=T),median = median(ER,na.rm=T),
            sd=sd(ER,na.rm=T),n=sum(!is.na(ER)),
            min=min(ER,na.rm=T),max=max(ER,na.rm=T)) %>%
  mutate(tcrit = qt(.975,df=(n-1))) %>%
  mutate(bound = tcrit*sd/sqrt(n)) %>%
  mutate(lower.95 = mean-bound) %>%
  mutate(upper.95 = mean+bound)

```

Graph the means by location (just for the newer model years)

Does there tend to be a systematic difference in the mean emission rates by location?

```{r}

summer.2022.loc.summary %>%
  filter(pollutant %in% c('CO','HC','NH3','NO')) %>%
  filter(year_cuts %in% c("(1994,2001]", "(2001,2016]" ,"(2016,2023]")) %>%
  ggplot(aes(x = year_cuts, y = mean, fill= location)) +
  geom_col(position = position_dodge(width = 1)) +
  geom_errorbar(position = position_dodge(width = 1), aes(ymin = lower.95, ymax = upper.95), width = 0.2) +
  facet_wrap(~ pollutant, scales = "free_y") +
  labs(title = "Comparison of Emissions Rates: by location",
       x = "Model Year Groups",
       y = "Emissions Rate") +
  theme(axis.text.x = element_text(size=8, angle=90,hjust = 1, vjust =0.2))

ggsave("../../CE594R_data_science_R/figs/ER_location.png")

```

Let's fit a model to the data that controls for the other factors, location, model year

Let's just focus on NH3 for now.

Create a new summer.2022.gas.NH3 data.frame from the summer.2022.gas

-   Filter to just NH3
-   Remove any rows with missing NH3 emission rate (column ER)
-   Just filter on the Compliant, non compliant and nonIM vehicles (exclude the exempt, since there are so few..)
-   Filter to Years less than 1993 (the newer vehicles which are capable of electronic emission tests)

```{r}

summer.2022.gas.NH3 <- summer.2022.gas %>%
    filter(Compliance %in% c("Compliant", "Not Compliant","NonIM")) %>% 
    filter(pollutant == 'NH3') %>%
    filter(Year>1994) %>%
    filter(!is.na(ER))

```

Fit a linear model

Use the model form: ER = intercept + location + Compliance + year + year\^2


```{r}
names(summer.2022.gas.NH3)


lm.NH3 = lm(formula = ER ~  location + Compliance + poly(Year,2),
            data = summer.2022.gas.NH3 )

```

Look at summary

```{r}

summary(lm.NH3)

```

How good is our model at explaining the variability of individual vehicles?
What is the R2?, Is it good?

0.05

Not very good at explaining the variability... but perhaps, it can help explain differences the impact the average emissions.

Is the Compliance coefficient significant?

-   No


Let's look at our model coefficients


```{r}
lm.Nh3.coef <- lm.NH3 %>%
               get_regression_table()


```

Get the predictions of your model to the data

```{r}
library(broom)

predict.summer.2022.gas.NH3 <- lm.NH3 %>%
                               augment(interval = 'confidence')

```

Plot your model estimates

Plot the NH3 emission rate on the y-axis Plot the model estimated (fitted) emission rates on the x-axis

```{r}

ggplot(data = predict.summer.2022.gas.NH3,aes(x = .fitted,y=ER)) +
    geom_point() +
    geom_abline(intercept=0, slope=1)+
    coord_cartesian(xlim = c(-0.5,14),ylim=c(-0.5,14))+
    scale_y_continuous(breaks = seq(0,14,2))+
    scale_x_continuous(breaks = seq(0,14,2))+
    theme_bw()
```

Now plot the predicted values (x-axis) vs. the residuals (y-axis) How do my residuals look like they are independent, and normally distributed with a constant variance across the predictors?

```{r}

ggplot(data = predict.summer.2022.gas.NH3,aes(y = .resid,x=.fitted)) +
    geom_point(alpha = 0.2,color='blue') +
    geom_abline(intercept=0, slope=0)+
    coord_cartesian(xlim = c(-0.5,14))+
    scale_y_continuous(breaks = seq(-2,14,2))+
    scale_x_continuous(breaks = seq(0,14,2))+
    theme_bw()
```

Not-- they don't look look normally distributed, and the variation appears to be changing

Also, look at the histogram and q-q plot of the residuals

```{r}


hg.resid <- ggplot(data = predict.summer.2022.gas.NH3,aes(x = .resid)) + 
  geom_histogram(bins=40)+
  theme_bw()+
  labs(x='residuals', y= 'count')  +
  theme(legend.position= 'none')


qq.resid <- ggplot(predict.summer.2022.gas.NH3, aes(sample=.resid)) +
    geom_qq()+
    geom_qq_line()+
    labs(title = 'Normal q-q plot',y='residuals', x='z-score') + 
    theme(legend.position = 'none')

hg.resid + qq.resid + plot_layout(nrow = 2)

```

How do the residuals look? Do you think I can assume that the residuals are approximately normal?

No, they are highly skewed

Should I trust my statistical tests from the multiple linear regression model? 

Probably not, unless the p-values are very small

Our linear model seems to be the wrong model fit to to our data. 
For example, It seems the the impact of location would be better modeled as a multiplicative factor. 

Let's try a log transformation of our y data.

Now, let's look if if we can have find a log-linear relationship

There is a good discussion of log-normal transformation here: 

<https://smogdr.github.io/edar_coursebook/transform.html#transformation>

And an example of using transformations in linear regression here: 
<https://smogdr.github.io/edar_coursebook/model.html#example-ols-linear-regression>

Let's calculate the ln(ER)

Note: you can't take the LN of any negative values.

Create a new data.frame called summer.2022.gas.NH3.pos

-   First, Remove all the negative NH3 emission rates (ER)
-   Calculate the ln(ER)

```{r}

summer.2022.gas.NH3.pos <- summer.2022.gas.NH3 %>%
                           filter(ER > 0) %>%
                           mutate(ln.ER = log(ER))
```

How many obs do we have now? How many did we lose?

```{r}
dim(summer.2022.gas.NH3)
dim(summer.2022.gas.NH3.pos)

dim(summer.2022.gas.NH3) - dim(summer.2022.gas.NH3.pos)

```

We had 5125 NH3 obs. We lost 938, and now have 4187 obs. 

Fit a linear model to predict the ln(ER) with additive terms for location, model year, and compliance, and interaction terms for each

```{r}

lm.ln.NH3 = lm(formula = ln.ER ~  location + Compliance + Year,
            data = summer.2022.gas.NH3.pos )

summary(lm.ln.NH3)

```

Not that these factors are additive in log-space. But multiplicative in real-space.


$$
ln(ER) = a*location+b*year+c*compliance
$$

$$
\exp(\ln(ER)) = \exp(a*location+b*year+c*compliance)
$$
$$
ER = \exp(a*location) * \exp(b*year) * \exp(c*compliance)
$$
In real-space, the impact of location, year, and compliance in our model are multiplicative. 

Looking at the graph of the mean emission rates by model year and location
A multiplicative effect of location on the emission rates looks like what we want. (For example, the Univ. Ave on NH3 looks ~ 2 times higher than the Timp HWY East for NH3 for each of the model year groups)

![](../../CE594R_data_science_R/figs/ER_location.png)

Graph to see if there are potential interaction terms between compliance and model year, and between model year and location, and between 


```{r}

names(summer.2022.gas.NH3.pos)

ln.NH3.year.loc.comp.summary <- summer.2022.gas.NH3.pos %>%
  group_by(pollutant, location, Compliance, year_cuts) %>%
  summarize(mean = mean(ln.ER, na.rm=T),median = median(ln.ER,na.rm=T),
            sd=sd(ln.ER,na.rm=T),n=sum(!is.na(ln.ER)),
            min=min(ln.ER,na.rm=T),max=max(ln.ER,na.rm=T)) %>%
  mutate(tcrit = qt(.975,df=(n-1))) %>%
  mutate(bound = tcrit*sd/sqrt(n)) %>%
  mutate(lower.95 = mean-bound) %>%
  mutate(upper.95 = mean+bound)

```

```{r}

  ggplot(data = ln.NH3.year.loc.comp.summary , aes(x = year_cuts, y = mean, color= Compliance)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(position = position_dodge(width = 0.5), aes(ymin = lower.95, ymax = upper.95), width = 0.2) +
  facet_wrap(.~ location, scales = "free_y") +
  labs(title = "Potential Interaction terms",
       x = "MY group",
       y = "ln(ER)") +
  theme(axis.text.x = element_text(size=8, angle=90,hjust = 1, vjust =0.2))

```
Looking at the graph, does it look like there are potential interaction terms?

- The slope with year, looks to be the same across model years

- The slope between compliance types looks signifiantly different. The Not Compliant slope with year looks like it is lower than the others

- I made another plot to look if there is a compliance X location effect. It looks like it is difficult to say...

```{r}

  ggplot(data = ln.NH3.year.loc.comp.summary , aes(x =location, y = mean, color= Compliance)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(position = position_dodge(width = 0.5), aes(ymin = lower.95, ymax = upper.95), width = 0.2) +
  facet_wrap(.~ year_cuts, scales = "free_y") +
  labs(title = "Potential Interaction terms",
       x = "MY group",
       y = "ln(ER)") +
  theme(axis.text.x = element_text(size=8, angle=90,hjust = 1, vjust =0.2))

```


Add 3 different interaction terms between Compliance, Year, and Location, are they significant?

Note: Section 14.2 describes how to fit an interaction term:

Linear Model With R, e-book at byu library

<https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=1910500>


```{r}

lm.ln.NH3 = lm(formula = ln.ER ~  location + Compliance + Year + Year:location + Year:Compliance +location:Compliance, 
            data = summer.2022.gas.NH3.pos )

summary(lm.ln.NH3)

```

Remove any interaction terms that are not significant (use p-value of 0.05). 

Based on your graphs, do the results make sense?

```{r}

lm.ln.NH3 = lm(formula = ln.ER ~  location + Compliance + Year + Year:Compliance,
            data = summer.2022.gas.NH3.pos )

summary(lm.ln.NH3)

```

Plot the residuals from this model

First put them into a data.frame


```{r}

predict.lm.ln.NH3 <- lm.ln.NH3 %>%
                     augment(data = summer.2022.gas.NH3.pos,interval = 'confidence') %>%
                     arrange(.fitted)

```

Then plot the fitted (x-axis) and the residuals (y-axis)


```{r}

ggplot(data = predict.lm.ln.NH3,aes(y = .resid,x=.fitted)) +
    geom_point(alpha=0.2) +
    geom_abline(intercept=0, slope=0)+
    theme_bw()
```

How do my residuals vs. predicted values looks?

They look much better, they look independent with constant variation

Let's also look at the histogram and q-q plot of the residuals

```{r}


hg.resid <- ggplot(data = predict.lm.ln.NH3,aes(x = .resid)) + 
  geom_histogram(bins=40)+
  theme_bw()+
  labs(x='residuals', y= 'count')  +
  theme(legend.position= 'none')


qq.resid <- ggplot(predict.lm.ln.NH3, aes(sample=.resid)) +
    geom_qq()+
    geom_qq_line()+
    labs(title = 'Normal q-q plot',y='residuals', x='z-score') + 
    theme(legend.position = 'none')

hg.resid + qq.resid + plot_layout(nrow = 2)

```


Look at the model coefficients, is the effect of compliance significant?


Store the coefficients in a data.frame table and then print them


```{r}
lm.ln.NH3.coef <- lm.ln.NH3%>%
               get_regression_table()

```

```{r}
library(tinytable)

tt(lm.ln.NH3.coef)
```

Question: What do the significant interaction terms mean?

Answer

Compliance: Not Compliant 

The ln(ER) intercept term is significantly lower for the Not Compliant emissions
Non-IM doesn't appear to be significantly different intercept than Compliant.

Compliance: Not Compliant:Year

The ln(ER) slope for the Not Compliant group is significantly different than the Compliant group.l 
For the Not Compliant Group the observations the slope is close to zero. 


To help us understand our model coefficients better, let's graph the results. 

Plot the model fit, like the picture below

![](../../CE594R_data_science_R/figs/Year_lnER_predict.png)

Plot different panels for each location

  - Plot Year on the x-axis
  - Plot the observed data on the y-axis using geom_point
  - Plot the predicted emission rate on the y-axis using geom_line

```{r}

ggplot(data = predict.lm.ln.NH3,aes(x = Year)) +
    geom_point(aes(y=ln.ER))+
    geom_line(aes(y=.fitted, color = Compliance), size = 1)+
    facet_grid(location ~ Compliance)+
    theme_bw()

#ggsave("../../CE594R_data_science_R/figs/Year_lnER_predict.png")
```

- Create the following plot of predictions and the standard error of the mean predictions

-Use geom_line for the predictions Use geom_ribbon for the standard error of the mean predictions

Only plot the predictions, so you can see differences.

Like InClass10

![](../../CE594R_data_science_R/figs/predict_lnER_comp.png)

```{r}

ggplot(data = predict.lm.ln.NH3,aes(x = Year, color=Compliance)) +
    geom_line(aes(y=.fitted), size = 1)+
    geom_ribbon(aes(ymin = .lower, ymax = .upper,fill=Compliance),alpha=0.3) +
    facet_wrap(~location)+
    theme_bw()

#ggsave("../../CE594R_data_science_R/figs/predict_lnER_comp.png")
```

Are the mean predictions significantly different by model year?

Answer:

-   The Compliant and non-IM vehicles don't appear to be different
-   The Non-Compliant have lower emission rates for the older Model years (pre-2005)

Next, Plot the model predictions in real-space,and compare to the real observations

Take the exponent of the predictions Plot the predicted values by Compliance Plot separate facets for Compliance level and Location

Re-create the following graph:

![](../../CE594R_data_science_R/figs/predict_lnER_comp_real.png)

```{r}

predict.lm.ln.NH3 <- predict.lm.ln.NH3 %>%
                     mutate(fitted_real = exp(.fitted)) %>%
                     mutate(lower_real = exp(.lower)) %>%
                     mutate(upper_real = exp(.upper))

ggplot(data = predict.lm.ln.NH3,aes(x = Year)) +
    geom_point(aes(y=ER))+
    geom_line(aes(y=fitted_real, color = Compliance),size=1)+
    facet_grid(location ~ Compliance)+
    theme_bw()

#ggsave("../../CE594R_data_science_R/figs/predict_lnER_comp_real.png")
```

Then compare just the mean model predictions and confidence intervals (remove the obs)

![](../../CE594R_data_science_R/figs/predict_lnER_real_conf.png)

```{r}
ggplot(data = predict.lm.ln.NH3,aes(x = Year, color=Compliance, fill=Compliance)) +
    geom_line(aes(y=fitted_real), size = 1)+
    geom_ribbon(aes(ymin = lower_real, ymax = upper_real,fill=Compliance),alpha=0.3) +
    facet_wrap(~location)+
    theme_bw()

#ggsave("../../CE594R_data_science_R/figs/predict_lnER_real_conf.png")
```

In the end, we fit a log-linear model that seemed to fit the data quite well. It also gave us some results that we were able to interpret. 


Before we pad ourselves on the back. What are some issues with our model fitting steps?

-   We threw out \~1000 negative values. What if there tended to be more negative values on the compliant or not compliant vehicles?...

-   Let's fit a non-linear smoothing function to the real (untransformed) data

-   Let's smooth by location and Compliance type

-   Let's plot those with the 95% confidence intervals

-   let's use Loess (localized regression smoothing, the default smoother in geom_smooth

-   You can adjust the 'span' to get a "good smooth"

![](../../CE594R_data_science_R/figs/NH3_smooth.png)

```{r}

names(summer.2022.gas.NH3)

ggplot(data = summer.2022.gas.NH3,aes(x = Year, y=ER,color=Compliance)) +
    geom_smooth(method = 'loess',span = 1.5,aes(fill = Compliance))+
    facet_wrap(~location)+
    theme_bw()

ggsave("../../CE594R_data_science_R/figs/NH3_smooth.png")

```

How do the model estimates from our log-linear model compare to our non-linear model?

Do the magnitude of our predictions change?

Yes! The University avenue predictions in 1995 changed from "\<" 1 mg. Now they are "\>" 1 mg/kg

Wait... shouldn't the predictions with the real-data be lower (since we included all the negative values?)

Let's think about the mean of exponent values

The exponent of the mean of the ln(x) is called the geometric mean-- and is not equal to the sample mean.

In other words:

exp(mean(ln(x))) != mean(x)

The mean of x will be more influenced by outliers. In our case, ln(x) reduces the distance to the positive outliers, the geometric mean is closer to the cloud of data at smaller values.

Do the relative order of the model estimates change regarding the compliance variables change?

Yes! Now the 'Not compliant' vehicles tend to have higher mean values across model years

Lessons:

Linear models with untransformed variables

Pros

- Can be easier interpret coefficients
- Fit will be to the mean of the data 
- Don't lose any negative variables

Cons

- The relationship may be non-linear 
- Residuals may be highly non-normal and can't run accurate diagnositcs 
- May need to make a complex linear model to fit the data (polynomial terms and interaction terms) that is difficult to interpret

Transformed variables 

Pros

- May be able to fit a linear form to a transformed variable (such as a log-linear relationship)
- May be able to correct the residuals to be approximately normal

Cons

- More difficult to interpret the results
- Our model doesn't fit to the mean of the real-data, but fits the mean of the transformed data
- This may discount the impact of outlier values, that may be very important to the mean statistic
- We may lose data

Non-linear models

Pros

-  Can fit the untransformed data, that have non-linear relationships

Cons

- Our residuals may still not meet the assumptions of normally distributed and identically distributed
- More complex methods to solve non-linear fits (we may not be guaranteed to find the optimal solution) 
- Communication: Non-linear models are more complex. People are unfamiliar with them than linear models


